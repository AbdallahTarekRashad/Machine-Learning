{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANN_CLA.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]}},"cells":[{"metadata":{"id":"ESNl5I0WpW2e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":377},"outputId":"a8282147-90bb-483b-de20-cb31ca88a801","executionInfo":{"status":"ok","timestamp":1524510566720,"user_tz":-120,"elapsed":8712,"user":{"displayName":"Abdallah Tarek","photoUrl":"//lh4.googleusercontent.com/-DNsuhHUTdXw/AAAAAAAAAAI/AAAAAAAAAxk/JjhsdVl_fok/s50-c-k-no/photo.jpg","userId":"111526412264331119039"}}},"cell_type":"code","source":["# Code to read csv file into colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 1. Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","#2. Get the file\n","downloaded = drive.CreateFile({'id':'1wDtYhmJuMUaGTNymPmQbiJYhF7MhDoZ4'}) # replace the id with id of file you want to access\n","downloaded.GetContentFile('train.csv')  \n","\n","downloaded = drive.CreateFile({'id':'1B3Y9ygdKTY3S_OPuZhSNyWRMkIiwt3Q3'}) # replace the id with id of file you want to access\n","downloaded.GetContentFile('test.csv')  \n","\n","\n","\n","import numpy as np \n","import pandas as pd\n","import tensorflow as tf\n","\n","train_db = pd.read_csv(\"train.csv\")\n","test_db  = pd.read_csv(\"test.csv\")\n","from keras.utils import np_utils\n","from keras.layers import Input, Dense, Dropout\n","from keras.models import Model\n","from keras.callbacks import ModelCheckpoint\n","\n","saved_weights_name='ANNWeights.h5'\n","\n","num_classes =3\n","y_train = train_db.loc[:,'class']\n","\n","print (\"y_train:\", y_train.shape)\n","\n","y_train = np_utils.to_categorical(y_train, num_classes)\n","print (\"y_train:\", y_train.shape)\n","print(y_train)\n","x_train = train_db.loc[:,'B':'R']\n","\n","print (\"x_train:\",x_train.shape)\n","\n","inp = Input(shape=(3,))\n","hidden_1 = Dense(100, activation='relu')(inp)\n","dropout_1 = Dropout(0.2)(hidden_1)\n","out = Dense(num_classes ,activation='softmax')(hidden_1)\n","model = Model(input=inp, output=out)\n","\n","\n","\n","\n","\n","\n","checkpoint = ModelCheckpoint(saved_weights_name, \n","                                     monitor='val_acc', \n","                                     verbose=1, \n","                                     save_best_only=True, \n","                                     mode='max')\n","\n","model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n","              optimizer='adam', # using the Adam optimiser\n","              metrics=['accuracy']) # reporting the accuracy\n","\n","model.fit(x_train, y_train, # Train the model using the training set...\n","          batch_size=500, nb_epoch=1,\n","          verbose=1, validation_split=0.1,\n","         callbacks=[checkpoint]) # ...holding out 10% of the data for validation\n","\n","\n","x_test = test_db.loc[:,'B':'R']\n","\n","print(np.argmax(model.predict(x_test))) # Evaluate the trained model on the test set!\n","\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["('y_train:', (145186,))\n","('y_train:', (145186, 3))\n","[[0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," ...\n"," [0. 0. 1.]\n"," [0. 0. 1.]\n"," [0. 0. 1.]]\n","('x_train:', (145186, 3))\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:51: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n","/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:71: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 130667 samples, validate on 14519 samples\n","Epoch 1/1\n","130667/130667 [==============================] - 1s 11us/step - loss: 5.0212 - acc: 0.6886 - val_loss: 3.2821e-04 - val_acc: 1.0000\n","\n","Epoch 00001: val_acc improved from -inf to 1.00000, saving model to ANNWeights.h5\n","2\n"],"name":"stdout"}]}]}